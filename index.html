<!DOCTYPE html>

<html>

<head lang="en">
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <meta http-equiv="x-ua-compatible" content="ie=edge">

    <title>GenArtist</title>

    <meta name="description" content="">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <link rel="stylesheet" href="./files/bootstrap.min.css">
    <link rel="stylesheet" href="./files/font-awesome.min.css">
    <link rel="stylesheet" href="./files/codemirror.min.css">
    <link rel="stylesheet" href="./files/app.css">




</head>

<body>
    <div class="container" id="main">
        <div class="row">
            <h1 class="col-md-20 text-center">
                <br></br>
                GenArtist: Multimodal LLM as an Agent for Unified Image Generation and Editing<br>
            </h1>
            <hr style="margin-top:0px">
        </div>
        <div class="row">
            <div class="col-md-12 text-center">
                <ul class="list-inline">
                    <li>
                        <a href="https://scholar.google.com/citations?user=x_-kOjoAAAAJ&hl=zh-CN/" style="font-size: 16px;">
                            Zhenyu Wang
                        </a>
                        <sup>1</sup>
                    </li>
                    <li>
                        <a style="font-size: 16px;">
                            Aoxue Li 
                        </a>
                        <sup>2</sup>
                    </li>
                    <li>
                        <a href="https://scholar.google.com/citations?user=XboZC1AAAAAJ&hl=en/" style="font-size: 16px;">
                            Zhenguo Li
                        </a>
                        <sup>2</sup>
                    </li>
                    <li>
                        <a href="https://xh-liu.github.io/" style="font-size: 16px;">
                            Xihui Liu
                        </a>
                        <sup>3</sup>
                    </li>
                    <br>
                    <a></a><br>
                    <li>
                        <sup>1</sup>
                        <a style="font-size: 16px;">
                            Tsinghua Unviersity
                        </a>
                    </li>
                    <li>
                        <sup>2</sup>
                        <a style="font-size: 16px;">
                            Noah's Ark Lab, Huawei
                        </a>
                    </li>
                    <li>
                        <sup>3</sup>
                        <a style="font-size: 16px;">
                            The University of Hong Kong
                        </a>
                    </li>
                </ul>
            </div>
        </div>


        <div class="row">
            <div class="col-md-4 col-md-offset-4 text-center">
                <ul class="nav nav-pills nav-justified">
                    <li>
                        <a href="https://arxiv.org/abs/2401.15688">
                            <img src="./files/paper.png" height="60px">
                            <h4><strong>Paper</strong></h4>
                        </a>
                    </li>

                      <li>
                       <!-- <a onClick="alert('Code coming soon!\nContact dengyu2008@hotmail.com for more details.')">  -->
                       <a href="https://github.com/zhenyuw16/GenArtist">
                            <img src="./files/github.png" height="55px">
                            <h4><strong>Code</strong></h4>
                        </a>
                    </li>
                </ul>
            </div>
        </div>

        <div class="row">
            <div class="col-md-12 col-md-offset-0 text-center">
                <a>
                    <video style="width:80%;height:80%;" playsinline autoplay loop preload muted>
                        <source src="./files/demo_short.mp4" type="video/mp4">
                    </video>
                </a>
                <br></br>
                <h2>
                    Abstract
                </h2>
                <hr style="margin-top:0px">
                <p class="text-justify" style="font-size: 16px;">
                    Despite the success achieved by existing image generation and editing methods, current models still struggle with complex problems including intricate text prompts, and the absence of verification and self-correction mechanisms makes the generated images unreliable. Meanwhile, a single model tends to specialize in particular tasks and possess the corresponding capabilities, making it inadequate for fulfilling all user requirements. We propose GenArtist, a unified image generation and editing system, coordinated by a multimodal large language model (MLLM) agent. We integrate a comprehensive range of existing models into the tool library and utilize the agent for tool selection and execution. For a complex problem, the MLLM agent decomposes it into simpler sub-problems and constructs a tree structure to systematically plan the procedure of generation, editing, and self-correction with step-by-step verification. By automatically generating missing position-related inputs and incorporating position information, the appropriate tool can be effectively employed to address each sub-problem. Experiments demonstrate that GenArtist can perform various generation and editing tasks, achieving state-of-the-art performance and surpassing existing models such as SDXL and DALL-E 3, as can be seen in Fig. 1. We will open-source the code for future research and applications.
                </p>
            </div>
        </div>

        <div class="row">
            <div class="col-md-12 col-md-offset-0 text-center">
                <br></br>
                <h2>
                    Video
                </h2>
                <hr style="margin-top:0px">
                <div class="text-center">
                    <div style="position:relative;padding-top:56.25%;">
                        <iframe src="https://www.youtube.com/embed/JdKCbUbsdRQ" allowfullscreen=""
                            style="position:absolute;top:0;left:0;width:100%;height:100%;"></iframe>
                    </div>
                </div>
            </div>
        </div>

        <div class="row">
            <div class="col-md-12 col-md-offset-0 text-center">
                <br></br>
                <h2>
                    Overview
                </h2>
                <hr style="margin-top:0px">
                <img src="./files/frame.png" class="img-responsive" alt="overview"><br>
                <p class="text-justify" style="font-size: 16px;">
                    Overview of GenArtist: . The MLLM agent is responsible for decomposing
                    problems and planning using a tree structure, then invoking tools to address the issues. Employing
                    the agent as the "brain" effectively realizes a unified generation and editing system.
                </p>
            </div>
        </div>



        <div class="row">
            <div class="col-md-12 col-md-offset-0 text-center">
                <br></br>
                <h2>
                    Generation Results
                </h2>
                <hr style="margin-top:0px">
                <p class="text-justify" style="font-size: 16px;">
                    GenArtist generates more accurate images given complex text prompts, compared to existing STOA text-to-image models including SDXL, LMD+, RPG, PixArt, Playground, Midjourney, DALL-E 3:
                </p>
                <!-- <video style="width:100%;height:100%;" playsinline autoplay loop preload muted>
                    <source src="./files/result.mp4" type="video/mp4">
                </video> -->
                <div class="col-md-12 col-md-offset-0 text-center">
                    <img src="./files/genex.png" class="img-responsive" alt="overview"><br>
                </div>
                <hr style="margin-top:0px">
                <p class="text-justify" style="font-size: 16px;">
                    GenArtist generates more accurate images given complex user instructions for the image editing tasks:
                </p>
                <!-- <video style="width:100%;height:100%;" playsinline autoplay loop preload muted>
                    <source src="./files/compare.mp4" type="video/mp4">
                </video> -->
                <div class="col-md-12 col-md-offset-0 text-center">
                    <img src="./files/editex.png" class="img-responsive" alt="overview"><br>
                </div>
                <p class="text-justify" style="font-size: 16px;">
                    The basic workflow and illustration for image generation tasks:
                </p>
                <div class="col-md-15 col-md-offset-1 text-center">
                    <img src="./files/generationstep.png" class="img-responsive" alt="overview"><br>
                </div>
                <p class="text-justify" style="font-size: 16px;">
                    The basic workflow and illustration for image editing tasks:
                </p>
                <div class="col-md-15 col-md-offset-1 text-center">
                    <img src="./files/editstep.png" class="img-responsive" alt="overview"><br>
                </div>
            </div>
        </div>

        <!-- <div class="row">
            <div class="col-md-12 col-md-offset-0 text-center">
                <br></br>
                <h2>
                    Manifolds Visualization
                </h2>
                <hr style="margin-top:0px">
                <p class="text-justify" style="font-size: 16px;">
                    GRAM constrains point sampling and radiance field learning on 2D manifolds, embodied as a set of
                    implicit surfaces. These implicit surfaces are shared for the trained object category, jointly
                    learned with GAN training, and fixed at inference time.
                </p>
                <video style="width:93%;height:93%;" playsinline autoplay loop preload muted>
                    <source src="./files/manifold.mp4" type="video/mp4">
                </video>
            </div>
        </div>

        <div class="row">
            <div class="col-md-12 col-md-offset-0 text-center">
                <br></br>
                <h2>
                    3D Geometry Visualization
                </h2>
                <hr style="margin-top:0px">
                <p class="text-justify" style="font-size: 16px;">
                    Although GRAM confines the input domain of the radiance field on 2D manifolds, we can still extract
                    proxy 3D shapes of the generated objects using the volume-based marching cubes algorithm. It can be
                    observed that GRAM produces high-quality geometry with detailed structures well depicted, which is
                    the key to achieve strong visual
                    3D consistency across different views.
                </p>
                <video style="width:100%;height:100%;" playsinline autoplay loop preload muted>
                    <source src="./files/shape.mp4" type="video/mp4">
                </video>
            </div>
        </div> -->

<!--         <div class="row">
            <div class="col-md-12 col-md-offset-0 text-center">
                <br></br>
                <h2>
                    Image Embedding and Editing
                </h2>
                <hr style="margin-top:0px">
                <p class="text-justify" style="font-size: 16px;">
                GAN inversion is naturally supported by GRAM. Given an input image, we can first embed it into the learned latent space and then freely move the camera viewpoint to synthesize images at novel views.
                </p>
                <video style="width:67%;height:67%;" playsinline autoplay loop preload muted>
                    <source src="./files/inv2.mp4" type="video/mp4">
                </video>
            </div>
        </div> -->

        <!-- <div class="row">
            <div class="col-md-12 col-md-offset-0 text-center">
                <br></br>
                <h2>
                    Responsible AI Considerations
                </h2>
                <hr style="margin-top:0px">
                <p class="text-justify" style="font-size: 16px;">
                    The goal of this paper is to study generative modelling of the 3D objects from 2D images, 
                    and to provide a method for generating multi-view images of non-existing, virtual objects. 
                    It is not intended to manipulate existing images nor to create content that is used to mislead or deceive. 
                    This method does not have understanding and control of the generated content. 
                    Thus, adding targeted facial expressions or mouth movements is out of the scope of this work. 
                    However, the method, like all other related AI image generation techniques, 
                    could still potentially be misused for impersonating humans. Currently, 
                    the images generated by this method contain visual artifacts, unnatural texture patterns, 
                    and other unpredictable failures that can be spotted by humans and fake image detection algorithms. 
                    We also plan to investigate applying this technology for advancing 3D- and video-based forgery detection.  
                </p>
            </div>
        </div>

        <div class="row">
            <div class="col-md-12 col-md-offset-0 text-center">
                <br></br>
                <h2>
                    Availability of Software
                </h2>
                <hr style="margin-top:0px">
                <p class="text-justify" style="font-size: 16px;">
                    Per concerns about misuse of this method, the code is available for use under a <a href="https://github.com/microsoft/GRAM/blob/main/GRAM-Microsoft%20Research%20License%20Agreement.pdf">research-only license</a>. 
                </p>
            </div>
        </div> -->
        
        <section class="section" id="BibTeX">
            <div class="container is-max-desktop content">
            <h2 class="title">BibTeX</h2>
            <pre><code>@article{wang2024div,
            author    = {Zhenyu, Wang and Enze, Xie and Aoxue, Li and Zhongdao, Wang and Xihui, Liu and Zhenguo, Li},
            title     = {Divide and Conquer: Language Models can Plan and Self-Correct for Compositional Text-to-Image Generation},
            journal   = {arXiv preprint arXiv:2401.15688},
            year      = {2024},
        }</code></pre>
            </div>
        </section>

        <!-- <div class="row">
            <div class="col-md-12 col-md-offset-0">
                <div class="text-center">
                    <h2>
                        Citation
                    </h2>
                </div>
                <hr style="margin-top:0px">
                <div class="form-group col-md-12 col-md-offset-0">
                    <div class="CodeMirror cm-s-default CodeMirror-wrap" style="font-size: 16px;">
                        <div
                            style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 4px; left: 4px; ">
                            <textarea autocorrect="off" autocapitalize="off" spellcheck="false"
                                style="position: absolute; padding: 0px; width: 1000px; height: 1em; outline: none;"
                                tabindex="0"></textarea></div>
                        <div class="CodeMirror-vscrollbar" cm-not-content="true">
                            <div style="min-width: 1px; height: 0px;"></div>
                        </div>
                        <div class="CodeMirror-hscrollbar" cm-not-content="true">
                            <div style="height: 100%; min-height: 1px; width: 0px;"></div>
                        </div>
                        <div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div>
                        <div class="CodeMirror-gutter-filler" cm-not-content="true"></div>
                        <div class="CodeMirror-scroll" tabindex="-1">
                            <div class="CodeMirror-sizer"
                                style="margin-left: 0px; margin-bottom: -17px; border-right-width: 13px; min-height: 162px; padding-right: 0px; padding-bottom: 0px;">
                                <div style="position: relative; top: 0px;">
                                    <div class="CodeMirror-lines">
                                        <div style="position: relative; outline: none;">
                                            <div class="CodeMirror-measure">AØ®A</div>
                                            <div class="CodeMirror-measure"></div>
                                            <div style="position: relative; z-index: 1;"></div>
                                            <div class="CodeMirror-cursors">
                                                <div class="CodeMirror-cursor"
                                                    style="left: 4px; top: 0px; height: 17.1406px;">&nbsp;</div>
                                            </div>
                                            <div class="CodeMirror-code" style="">
                                                <pre
                                                    class=" CodeMirror-line "><span style="padding-right: 0.1px;">@article{wang2024div,</span></pre>
                                                <pre
                                                    class=" CodeMirror-line "><span style="padding-right: 0.1px;"> &nbsp;  title={Divide and Conquer: Language Models can Plan and Self-Correct for Compositional Text-to-Image Generation},</span></pre>
                                                <pre
                                                    class=" CodeMirror-line "><span style="padding-right: 0.1px;"> &nbsp;  author={Zhenyu, Wang and Enze, Xie and Aoxue, Li and Zhongdao, Wang and Xihui, Liu and Zhenguo, Li},</span></pre>
                                                <pre
                                                    class=" CodeMirror-line "><span style="padding-right: 0.1px;"> &nbsp;  journal={***},</span></pre>
                                                <pre
                                                    class=" CodeMirror-line "><span style="padding-right: 0.1px;"> &nbsp;  year={2024}</span></pre>
                                                <pre
                                                    class=" CodeMirror-line "><span style="padding-right: 0.1px;">}</span></pre>
                                            </div>
                                        </div>
                                    </div>
                                </div>
                            </div>
                            <div style="position: absolute; height: 13px; width: 1px; top: 280px;"></div>
                            <div class="CodeMirror-gutters" style="display: none; height: 300px;"></div>
                        </div>
                    </div>
                </div>
            </div>
        </div> -->

        <!-- <div class="row">
            <div class="col-md-12 col-md-offset-0 text-center">
                <br></br>
                <h2>
                    Acknowledgements
                </h2>
                <hr style="margin-top:0px">
                <p class="text-justify" style="font-size: 16px;">
                    We thank Harry Shum for the fruitful advice and discussion to improve the paper. <br>
                    The website template was adapted from <a href="https://jonbarron.info/mipnerf/">Mip-NeRF</a>.
                </p>
            </div>
        </div> -->


</body>

</html>
